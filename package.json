// orchestrator.js
import { estimateCost } from "./pricing.js";

/**
 * Auto-orchestrator:
 * - Try models in preferred order
 * - Exponential backoff retries for transient errors (429, 502, 503, 504)
 * - On quota / permanent errors, fallback to next cheaper model
 *
 * Exports:
 * - runTask(openai, userInput, tone)
 * - getStatus() -> returns recent history & counters for admin page
 */

// In-memory history for admin page (keeps last 50 entries)
const HISTORY_LIMIT = 50;
const history = [];

// Candidate models ordered: higher perf first, cheaper later
const MODEL_CANDIDATES = [
  "gpt-5-mini",
  "gpt-4.1",
  "gpt-4o-mini",
  "gpt-4o",
  "gpt-3.5-turbo" // fallback cheap
];

// Helper to record history
function pushHistory(entry) {
  history.unshift({ ts: new Date().toISOString(), ...entry });
  if (history.length > HISTORY_LIMIT) history.pop();
}

// sleep helper
function sleep(ms) {
  return new Promise((r) => setTimeout(r, ms));
}

function isTransientError(err) {
  const message = (err?.message || "").toLowerCase();
  const code = err?.status || err?.statusCode || err?.code || "";
  // transient: rate-limit, server overload, timeouts, 5xx
  if (String(code).startsWith("5")) return true;
  if (code === 429) return true;
  if (message.includes("rate limit") || message.includes("quota") || message.includes("exceeded")) {
    // quota may be not transient — return false to trigger fallback instead of retry
    // we treat 'exceeded your current quota' as NOT transient so we fallback
    if (message.includes("exceeded") || message.includes("quota")) return false;
    return true;
  }
  if (message.includes("timeout") || message.includes("timed out")) return true;
  if (message.includes("server error")) return true;
  return false;
}

/**
 * attemptCompletion: try the openai call with backoff for transient errors (but no model fallback here)
 */
async function attemptCompletion(openai, model, messages, maxRetries = 3) {
  let attempt = 0;
  let backoffMs = 500; // initial backoff

  while (true) {
    try {
      // call OpenAI Chat Completions
      const response = await openai.chat.completions.create({
        model,
        messages,
      });
      return response;
    } catch (err) {
      attempt++;
      const transient = isTransientError(err);

      // If non-transient or we've exhausted retries, rethrow so caller can decide to fallback model
      if (!transient || attempt > maxRetries) {
        err.attempts = attempt;
        throw err;
      }

      // transient: sleep and retry
      console.warn(`Transient error on model ${model}, attempt ${attempt}/${maxRetries}: ${err.message}. Backing off ${backoffMs}ms...`);
      await sleep(backoffMs);
      backoffMs = Math.min(5000, Math.round(backoffMs * 2.5)); // increase
    }
  }
}

/**
 * runTask(openai, userInput, tone)
 * - returns { model, response, usage }
 */
export async function runTask(openai, userInput, tone = "auto") {
  const normalized = (tone || "auto").toLowerCase();
  const tonePromptMap = {
    auto: "",
    humorous: "Respond in a funny, witty tone.",
    supportive: "Respond in a kind and supportive tone.",
    creative: "Respond in a creative, imaginative way.",
    informative: "Respond in an informative, factual tone.",
    neutral: "Respond neutrally and clearly."
  };
  const tonePrompt = tonePromptMap[normalized] || "";

  const systemMsg = {
    role: "system",
    content: "You are NexMind.One — The Oracle of Insight. A smart, adaptive AI companion."
  };
  const userMsg = {
    role: "user",
    content: `${tonePrompt}\nUser: ${userInput}`
  };

  // Try models in order; for each, attempt retries for transient errors using attemptCompletion
  for (const model of MODEL_CANDIDATES) {
    try {
      const response = await attemptCompletion(openai, model, [systemMsg, userMsg], 3);

      const text = response?.choices?.[0]?.message?.content || "";
      const promptTokens = response?.usage?.prompt_tokens || response?.usage?.promptTokens || 0;
      const completionTokens = response?.usage?.completion_tokens || response?.usage?.completionTokens || 0;
      const estimatedCost = estimateCost(model, promptTokens, completionTokens);

      const rec = {
        model,
        success: true,
        promptTokens,
        completionTokens,
        estimatedCost,
        error: null,
      };
      pushHistory(rec);

      return {
        model,
        response: text,
        usage: {
          promptTokens,
          completionTokens,
          estimatedCost
        }
      };
    } catch (err) {
      // If the error indicates a quota-exceeded or permanent failure, try next model (fallback)
      const message = (err?.message || "").toLowerCase();
      const status = err?.status || err?.statusCode || err?.code || null;

      pushHistory({
        model,
        success: false,
        error: String(err?.message || err),
        status
      });

      // If error message strongly indicates quota/exceeded, fallback to next model
      if (message.includes("exceeded") || message.includes("quota") || status === 401) {
        console.warn(`Model ${model} returned non-retryable error (${status}). Falling back to next candidate.`);
        // continue loop to attempt next model
        continue;
      }

      // For other errors, we already retried in attemptCompletion; now continue to next model
      console.warn(`Model ${model} failed (status=${status}) — trying next candidate. err: ${err?.message}`);
      continue;
    }
  }

  // If we reach here, all models failed
  const finalError = new Error("All models failed or quota exceeded for all models.");
  pushHistory({
    model: "all",
    success: false,
    error: finalError.message
  });
  throw finalError;
}

/** Admin utilities */
export function getStatus() {
  // Summary: last 20 entries + counts
  const recent = history.slice(0, 20);
  const counts = history.reduce((acc, item) => {
    acc.total = (acc.total || 0) + 1;
    if (item.success) acc.success = (acc.success || 0) + 1;
    else acc.fail = (acc.fail || 0) + 1;
    return acc;
  }, {});
  return {
    recent,
    counts
  };
}
